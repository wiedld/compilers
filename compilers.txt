COMPILERS

1. frontend:
    - Lexical analysis = Tokenize
        1- recognize which substrings are the lexemes
        2- classify substrings by their role (token class)
        - token classes: identifiers, ints, strings, parans, keywords, whitespace
        - approach: reading left-to-right, lookahead may be required, can use regex to recognize token classes
    - Syntax analysis = Parsing
        - regex parsers, LL(k), LR(k)
        - output is not the tree per se (e.g. tree doesn't need to be built). Instead, is the tree traversal in your code.
        - in-order (left child, parent (op), then right child)
        - pre-order (parent, then children) = LL(k) = top-down = predictive
        - post-order (children, then parent) = LR(k) = bottom-up = shift-reduce
    - Semantic analysis = Binding
        - (type checking, object binding, issuing warnings for invalid inputs)

2. middle:
    - Code optimisation:
        - done in a language other than source or machine code
        - once we have the semantic meaning assigned, we can re-translate to the syntax which runs more efficiently. (since many difference syntax can be written for the same sematic meaning)
    - intermediatary layer, often used for generic optimization (shared with other compilers)

3. backend:
    - additional analysis
    - transformations
    - tends to be specific for that computer etc.
    - generates the actual machine code to execute


###########################
###########################
LL(k):
    - onto stack if:
        - non-term, not yet expanded
        - term, not yet matched
        - top = leftmost pending term or non-term
    - reject with error state
    - accept on end of input w/ empty stack


###########################
###########################
